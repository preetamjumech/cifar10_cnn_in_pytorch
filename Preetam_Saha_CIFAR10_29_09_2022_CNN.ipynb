{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hikexqAoDuw8q7g0i3T4G_NqkGYFiT0m",
      "authorship_tag": "ABX9TyNKXBnnRE0sEKrcYI3MJkeU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preetamjumech/cifar10_cnn_in_pytorch/blob/main/Preetam_Saha_CIFAR10_29_09_2022_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "blccSROGu0T5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test,y_test) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_XUKMAUxEDB",
        "outputId": "3eaeaffd-b4c9-4316-c47a-fdeef816042e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKFHy7SixKyU",
        "outputId": "88ef5afc-d85b-4ac3-8bf4-b180dadf856d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkwP45Knxcoc",
        "outputId": "544ec5fd-5968-4a19-ef1d-1133e38bd204"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLWB3QcDxc2I",
        "outputId": "5eb15632-7e90-4483-a923-648732f9b040"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOctxEDexzoH",
        "outputId": "0a3010a6-2c3d-479c-f508-7a5b24742f2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchsummary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, RMSprop\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fbRoyHK6xc5X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.tensor(x_train)\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvG5qlyTxeE_",
        "outputId": "78d06b63-26a9-449f-b1dd-c0d73b8bf775"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 32, 32, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1,3,32,32)\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAnmApuSx6ls",
        "outputId": "9338a8b6-7a8e-4ac5-9a0a-b942b36e427a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.tensor(y_train)\n",
        "x_test = torch.tensor(x_test)\n",
        "y_test = torch.tensor(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xLZGbL5yBZt",
        "outputId": "10d7aa5a-82b8-4809-8b4e-200818eeea61"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape , y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKdrOpfvyafD",
        "outputId": "f68759a4-0b3a-4506-995b-4c796b437110"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10000, 32, 32, 3]),\n",
              " torch.Size([50000, 1]),\n",
              " torch.Size([10000, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.reshape(-1,3,32,32)\n",
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVxY1f5vypDn",
        "outputId": "dd84b368-4432-498e-f6ee-095a3d864df2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "idx = 3\n",
        "Image.fromarray(x_train[idx,0,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "JeQDIK5byweM",
        "outputId": "013dfa94-b672-4482-da4c-81d2495a9f0c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=32x32 at 0x7F6D320C3C90>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADqElEQVR4nAXBW1MbVQAAYE4amgSkTTYkkGzIfSEJpNyhWMe20hcdR190nFFn/KE+Ojo6OhSmtQ0tCGSTzdnL2XPJ7jl7y+L3gcqMyjOan9FiyAohezyjUkzBPVvxeYV4ixwsFOPpasTWItaIpnMR+0RwyeNLQkgeL/juKthgioOPiLngmEXf3vCp5Llpj+6LUU+oPaGCRkgLEZFCKgc0F9DVkBQiUoxwy8cSoxkOku2QKII2BVU487iT80jdwxseSXmk7uM98KVVc80TNik6BvCQ4iHFt/LCOJ6Ou0xbm47Bho9LPun4eCm0CwHOB3jVI7uBtSeM2DFXOcgfemaN0Rql25Q+YEzm5hNudoWRFsaBP+mAH7QiHz9z1Z6rL3FUF3rbU6vu6AmGx7a+ZuvgyLObPtrxUTJCtRBlfHuH4yY3+0Jb5to2B89qLuxiu2fjEsZtbDfdSY9rVa6tca0r1FaiMMjVB7nyRZx8M/fwLFe6Kqxfporvc8VRUb5OZwfgKw+VPNQQqDUzm6GVEuiI4TIzJD7aF+qWSEzlOlLWSVuxE/NnwexWKv8Vz7+OMh9y7bfRo99AYvnNo9q5SP4aJD8uFi6LzetU6Ty1OkjlzoLk+ePyOfiamyuuVXet9kyvRnqVW+sEtbFRcUayr+7zxE2piqoto9IY5cvqYv7jgnSeyV3MZwdSy6r0PywnlH/T5ffp8iBbv8pVh5WeNV+8cJJ/JLNn8cI/+dZNYiZd3ucu57IX3qNzJ/17vAhrnWj/hMr1Ybb25+xhYpBZeidVbkstfUWh+do7SX67kP1bKo3b22L9gMrgm2FVaO0Q9gVsMNikRo5ZFYYOHUt2UG2KwLeuUXXMnmuU4kkjmshTc9tEr6CVpVD2tS0HPK3a8MS7W/PuNry7PTGsM9imep/BXQprZLwOvhu3BZRCSxFGk06q1FohtEnZFrckYWaECQ5CshySekgasbUS2G1CvtC1E1OViLbFhp9Z4MULXe2z2zS7ec6u+9OrLlH3bNjXzQMIn5jGJvh+Up5qMscKsw8R3EVGEqETjBRHrzt63oGgH7M4ZuV71pjhkjfdQuz5ZLhv/rdJRzvm3ada8sFPo9slWz20717i6wP88XPyend+0Amvj+cHvfj1AfgZZuiow/AhJk0L7liwbMFTBEtMX5vC/hSC0wDdB7YSoFKAmi49RvjpRO2aw00Mj4zRLyPwY2s0fGzrr/CkQ9QOvT1lN117sgmNPW1chkbvf6n1alN9EN+7AAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray(x_train[idx,1,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "-dxgxqOBy7kn",
        "outputId": "2de73454-e31d-4861-b79a-5234169d5140"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=32x32 at 0x7F6D320C3B10>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAD5ElEQVR4nAXBWVNbVQAA4Dmh1JYp2IqQgEACCQlkgbBkJRXaQsVSDHaktAx2pq59cUad1un4oL7woq/+A19890FfdJyBNkNV1pYQ7nLuOffc9dwluWG1rfh9YEKJl4nPMfvKZthSg5aatpWeiurapx37dGSfuuo8G6ebYUsne76lVH2xXPfqUoeXqTlNuwLV/lhpKOz6L9DBvXJutd1Pz73mhMK7kYFHoH4nFFVCwWd19T85YFK6aJOeCu2p6IMVKVaWe8ry2ariOTI7jkz/kelqbH9c795uain6guzJmWXD+UUz/6o5wzReILGg6XeDQT8mYaucs6yATf1luc/hohWx35aSNp+hKAHmcdQi4bIacOS4I4YcMeCInXty4NhqOba8x5arPch3BOHA8F4yY3dH9J541Tj4wzleOnm+1VC77j0P+pMIdVArZhhpU0uY5E2bvWyKF20xU2bjlHWD99GwQYK21FUm8QqOV1CogqJVqfvQdB+arYemq8W/2R4QBlJHiaQ+lFT7M1Xt4Fe69+fzg/X6mvWJ1KnNeYEJ1KykXm6NuZm0m+t8cbCo4WmK+y2mVyt5wGcwSEnEQmkbxm2h3xJSFvKVxWhVa9rTvFUd3DJIjpIRSi5hMSvyOR2eVMw2y5lQzCGMF3nw4Sy/NSLCccJNktIE2Qkh9i4m70nkGt2NqNuN4Hs+oEkBQ8gafFZDgyrKakKnjlO27CnLSVsG75hywpISpjQj4JzApnUuWDGPbGdG1qdEbpEH92fZf6b44rvw6RzcvAHXkww3xpEZLF5Xd99SttrAj2xYldwmN6KzkwSPiGJCxDFJTBi428ApKoIZS+01lSxVriE0gXfTGtdl6Xu0epOoXwvFr1jw4JPdJ7f5zSm4MQ1Xb8LVt5ntDCMOy3KrhuY1pht8K7apSsxgpuXdSShMQpQTcATjrIRyihDRBHBPNwZULSOpORmmFDatCGGVNIl2nld+YDe+LIKHXxQL82htGq9eRqsL+O88WYnysLVCX9pWgtoekHe8Op3VmOu4OM6weY4fE2BKQDmIxwjy6xB8ahopTR+W1REVRlV+WME5WUqJRhbKD9nNz4vgm3s7hQVUWECFPCrcwY/nUCHGQKtqNFedXmPfA64eBLTKDU0YJ6VRyI5ifkgSRok4RMiwgsIaBHcts4/SjKZGdGGAwjFdTGqKT6ZJIj2Az+6XwHd3Sk8+gMsf8ct5uPQxXJrjHl3ZYTer9I3jPZ995AWj/wb0/auaklS4KzLXpwleAw+YUp+h9BliVoeuhto1n+d3UPvb8dmfa5tXTl0oNvm2G15f93jWksmnt2/9D6HXfEM3YQRDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray(x_train[idx,2,:,:].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "WGA_RSKNzCxz",
        "outputId": "f2e9ed07-496c-44e4-cba8-a7c16f531d33"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=32x32 at 0x7F6D3202E990>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAD1klEQVR4nAXB227aZgAAYH6HJJCQ4IDBgMHhFDCQY5NNTdO0atpV7XW1TrvppqmTJu1uT7CH2KtMm7RcrJMaNUmjhajtNrAx4Pj4Y5uAD9gGsu8Dr1826z8x59/T75/S56/os5eNkxcfmn8OVG8yWr8Zr4GtaQW692W1CDt3VbZ80yYNrmwKJUMp9/kNlUWAfbwS+F3r/xrOnC5lGnOxFppmsXQHT32KJ0+ePAXP1lvM1zT9Fc3k6dYXDPNL4/y7q8bHG8UG1rIxzoG0b7033oc3SZ3PD7sbNkeOhIIrEy6MWsJdvYug86eL/t8c5wxNt5OVLkoqCzE2uNJZCLcLlYvtXfBgrgMfsr3Nlr7bUg/a0s+t+g/1pqdfL4CBazpFkJ3E1PHz3jDRl1IWTzhi2lMSY1iayKgrbhoCOHR0yu6tGRA3xQ1TIg1IGFrehCWT29DZ+zJizI3fRhY/5tPDUlEILzV3q+I3RxMsdmmu1OHMHya44wQ1r6wOnvQVzFSiTg/3tOC0dzDlY2Mx7irIFIhJnC5Sf7sB2rd8HctaEQKQtaYv2lnEu1EMmcbD7OZmh0jLSbJHFliqID+r6TtbCpJkVP87DZSGh/3RWO8/v4EJQ5ux+7gzyHjq4bgTmgoEUMG9iRb1elsjmHNkYqSUbTVp62lXyblcweDyPcQIBfn9B1pylckU5VDkfSxO72ev97bVAMH4og0PbGtH/eGSrlb6cHWoLVl62RnkXZXw2oGpQIA+OJrC5ERJeUp+JFOWVLLkgqVkHWnTE3CTT+kInF/4J7+u5yvyapFD5s/GM3+tEUwmfooELsM4nQVfspkb7rDHb2kSafG7dqc04pMjBXOFVU9MjiEyDNMo9RHgV0ikGcpcemjdCzX8mBCrDkIpIRpHuiH0AiU6y7GGP3gxu/AJy7RqVUgmriLRRrnGVMGrRmnQOoDdx6qI2Vx1ROesDmlLlCutuhLpSOCFBQsWTFsKZYm4JZYssWKLNUcouwJp8KSG0GtlIVkQChUhuzaqbZmFdSmfb6bwq0SqkS1yVfCa2Rmye5Df06S4fV20W5TFlWw568qYK2OujBjzb8y5Y3f22PBdDWffDRfPZhP/+bHGTJTDSC1X9HOfYZ2dRJcKcwe4vJVS8hF2w0cf+FuPwuzGTP0h+LFNDbqUKtzRIGnxZbtdsq7TNlx2Ie7CnAsRa+at4z8BwTe3gatb9NJF674IM5ql/SiNZ9hMxv/h80CjusBUAv/uIK39kET6W9Vbfnu5+5hsU/MX98C33ZR5TWjyvqZGLLFmtymbj1oq6qgFRy046v/J5jOakJ9g+QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.reshape(-1,)\n",
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzwugXVUzGQb",
        "outputId": "3a860446-5db4-4d8f-8810-bd925389b8d6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(-1,)\n",
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "335tMFBdzJKQ",
        "outputId": "7f328591-061c-4635-d2f4-d3f90a50cf80"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgVQ1rg25Kaq",
        "outputId": "fd810c59-879f-4ca4-de0d-d2b98ca03d0c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 9, 9,  ..., 9, 1, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "BdoBu-zNz_C9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CuJSp9l0Ee7",
        "outputId": "fc15ced2-79b5-454f-a940-77f0d6e098d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CIFAR_CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=16, kernel_size=3, padding=1 ) #in_channel = channel, out_channels=no of filters, kernel_Size = filter size\n",
        "    self.conv2 = nn.Conv2d(in_channels=16,out_channels=32, kernel_size=3, padding=1 )\n",
        "    self.conv3 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=3, padding=1 )\n",
        "    self.conv4 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=3, padding=1 )\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=16)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=32)\n",
        "    self.bn3 = nn.BatchNorm2d(num_features=64)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride = 2) #by pooling only reduction happenes, stride = 2 means jump of 2 pixels\n",
        "    self.h1 = nn.Linear(in_features=2*2*128, out_features= 512)\n",
        "    self.h2 = nn.Linear(in_features=512, out_features= 256)\n",
        "    self.h3 = nn.Linear(in_features= 256, out_features= 32)\n",
        "    self.out = nn.Linear(in_features = 32, out_features=10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = self.bn3(x)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = self.pool(x)\n",
        "    #print(x.size())\n",
        "\n",
        "    x = x.view(x.size()[0],-1)\n",
        "    #print(x.size())\n",
        "\n",
        "    x = F.relu(self.h1(x))\n",
        "    x = F.relu(self.h2(x))\n",
        "    x = F.relu(self.h3(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "6pP5vVE-0DMF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = CIFAR_CNN()"
      ],
      "metadata": {
        "id": "OAojDlMI0afF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(cnn_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6h9ahAJ0gjX",
        "outputId": "0a38316e-daef-461e-d270-9e612ea547a7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[[[-0.0368,  0.0393, -0.0975],\n",
              "           [ 0.0071, -0.1781,  0.1818],\n",
              "           [ 0.0591,  0.1788, -0.0823]],\n",
              " \n",
              "          [[-0.1858, -0.1249,  0.0331],\n",
              "           [ 0.1845, -0.1607, -0.1039],\n",
              "           [ 0.0993, -0.1633, -0.0403]],\n",
              " \n",
              "          [[-0.1273, -0.1249, -0.0218],\n",
              "           [-0.1469, -0.1876,  0.1553],\n",
              "           [-0.1436, -0.1536,  0.1644]]],\n",
              " \n",
              " \n",
              "         [[[-0.1607, -0.1220, -0.1002],\n",
              "           [ 0.0804, -0.0247, -0.0704],\n",
              "           [ 0.1399, -0.0126,  0.1651]],\n",
              " \n",
              "          [[-0.1902, -0.0367, -0.0691],\n",
              "           [ 0.0937,  0.1552,  0.0993],\n",
              "           [-0.1856, -0.1520,  0.0547]],\n",
              " \n",
              "          [[-0.0411,  0.0152, -0.0400],\n",
              "           [ 0.1108,  0.1732, -0.0804],\n",
              "           [ 0.1882,  0.0290, -0.1758]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0908,  0.1200, -0.0507],\n",
              "           [ 0.0787,  0.0255, -0.0698],\n",
              "           [-0.1543, -0.1497,  0.1603]],\n",
              " \n",
              "          [[ 0.1528,  0.1636,  0.1079],\n",
              "           [ 0.0327,  0.1290,  0.1898],\n",
              "           [ 0.1432,  0.0982,  0.0577]],\n",
              " \n",
              "          [[-0.0407,  0.1202,  0.1904],\n",
              "           [ 0.1146, -0.0380, -0.1127],\n",
              "           [-0.1706,  0.1290,  0.0581]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1092,  0.1911,  0.1782],\n",
              "           [-0.0107,  0.1016,  0.0107],\n",
              "           [ 0.0535, -0.1186,  0.1217]],\n",
              " \n",
              "          [[ 0.0609,  0.0190,  0.1415],\n",
              "           [-0.0486, -0.0354,  0.1269],\n",
              "           [-0.0503,  0.0393,  0.0179]],\n",
              " \n",
              "          [[ 0.0027,  0.0944,  0.0552],\n",
              "           [ 0.0885, -0.1879,  0.0331],\n",
              "           [-0.1653,  0.1773,  0.0412]]],\n",
              " \n",
              " \n",
              "         [[[-0.1759, -0.1604,  0.1785],\n",
              "           [ 0.1427,  0.0372, -0.0124],\n",
              "           [ 0.1476, -0.0152, -0.1234]],\n",
              " \n",
              "          [[ 0.0681, -0.1619, -0.1195],\n",
              "           [-0.0741, -0.0618, -0.1456],\n",
              "           [ 0.0931,  0.1267,  0.0281]],\n",
              " \n",
              "          [[-0.1235, -0.1776,  0.0573],\n",
              "           [ 0.1650,  0.0946,  0.0869],\n",
              "           [ 0.1785, -0.0172,  0.1477]]],\n",
              " \n",
              " \n",
              "         [[[-0.0460,  0.0310,  0.1571],\n",
              "           [-0.0013, -0.1507, -0.0425],\n",
              "           [-0.0193, -0.1487, -0.0425]],\n",
              " \n",
              "          [[ 0.0175, -0.0896,  0.1168],\n",
              "           [ 0.1048, -0.1878,  0.0316],\n",
              "           [ 0.0801,  0.1685,  0.1537]],\n",
              " \n",
              "          [[-0.1457, -0.0676,  0.0152],\n",
              "           [ 0.1329, -0.0189,  0.0432],\n",
              "           [ 0.1900,  0.0214,  0.0049]]],\n",
              " \n",
              " \n",
              "         [[[-0.0993,  0.0156,  0.0300],\n",
              "           [ 0.0204,  0.1354, -0.0911],\n",
              "           [-0.1647,  0.0835, -0.1632]],\n",
              " \n",
              "          [[ 0.1176,  0.1865, -0.1336],\n",
              "           [-0.1586,  0.0661,  0.1372],\n",
              "           [ 0.0760,  0.0262,  0.0228]],\n",
              " \n",
              "          [[-0.1630, -0.0567, -0.1408],\n",
              "           [-0.1034,  0.1747,  0.0644],\n",
              "           [ 0.0605, -0.0844, -0.1906]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1898, -0.0392,  0.1723],\n",
              "           [ 0.1840,  0.0421,  0.0751],\n",
              "           [-0.1168, -0.1405,  0.1529]],\n",
              " \n",
              "          [[-0.1687,  0.0408,  0.0161],\n",
              "           [-0.0381,  0.0315, -0.0264],\n",
              "           [ 0.1643,  0.0885,  0.1364]],\n",
              " \n",
              "          [[-0.1908, -0.1785, -0.1881],\n",
              "           [-0.0148, -0.0919,  0.0322],\n",
              "           [ 0.0867,  0.0423, -0.1825]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1478,  0.0199,  0.0847],\n",
              "           [ 0.1123,  0.1044, -0.1417],\n",
              "           [ 0.1733,  0.1152,  0.1441]],\n",
              " \n",
              "          [[-0.0483,  0.0779, -0.0270],\n",
              "           [ 0.1701,  0.0691, -0.0261],\n",
              "           [-0.1753, -0.1711,  0.1547]],\n",
              " \n",
              "          [[-0.0945,  0.1236,  0.0962],\n",
              "           [ 0.1909,  0.0592, -0.0111],\n",
              "           [-0.0593,  0.0825, -0.0837]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0062,  0.0610, -0.1337],\n",
              "           [ 0.1013, -0.0022,  0.0689],\n",
              "           [ 0.0868,  0.0419, -0.0819]],\n",
              " \n",
              "          [[ 0.1923, -0.1314, -0.1116],\n",
              "           [ 0.0209, -0.1013, -0.1016],\n",
              "           [ 0.0161, -0.0805, -0.0804]],\n",
              " \n",
              "          [[ 0.0785, -0.1072,  0.1413],\n",
              "           [ 0.0035,  0.0755,  0.0289],\n",
              "           [ 0.0501,  0.0604,  0.0419]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1354,  0.0002, -0.0834],\n",
              "           [ 0.0816,  0.0997,  0.1793],\n",
              "           [ 0.1139, -0.0214,  0.1064]],\n",
              " \n",
              "          [[ 0.1124,  0.0081, -0.0747],\n",
              "           [ 0.1901,  0.0484,  0.1520],\n",
              "           [-0.0995,  0.0125,  0.1563]],\n",
              " \n",
              "          [[ 0.0058,  0.1371, -0.1577],\n",
              "           [ 0.0206,  0.0212,  0.0064],\n",
              "           [-0.1371, -0.0022, -0.0722]]],\n",
              " \n",
              " \n",
              "         [[[-0.0534,  0.0803, -0.1663],\n",
              "           [ 0.0861,  0.0641, -0.0604],\n",
              "           [ 0.0220,  0.1819, -0.0752]],\n",
              " \n",
              "          [[ 0.1379, -0.0359,  0.1451],\n",
              "           [-0.0622, -0.1212, -0.0237],\n",
              "           [-0.1828, -0.1076, -0.0126]],\n",
              " \n",
              "          [[-0.0899,  0.0732, -0.0489],\n",
              "           [-0.1792, -0.0414, -0.0968],\n",
              "           [ 0.1171,  0.0353,  0.1699]]],\n",
              " \n",
              " \n",
              "         [[[-0.0292, -0.0488, -0.0936],\n",
              "           [ 0.0028,  0.1300, -0.1625],\n",
              "           [ 0.1519,  0.0945, -0.1654]],\n",
              " \n",
              "          [[-0.0384,  0.0789,  0.0854],\n",
              "           [-0.0523,  0.0383,  0.1695],\n",
              "           [-0.0909, -0.1471,  0.1047]],\n",
              " \n",
              "          [[ 0.0717,  0.1435, -0.0079],\n",
              "           [-0.1002,  0.0891, -0.0724],\n",
              "           [ 0.1479,  0.0791, -0.1399]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0687, -0.0646, -0.0437],\n",
              "           [-0.1857,  0.1288, -0.0603],\n",
              "           [ 0.1259,  0.0710, -0.1604]],\n",
              " \n",
              "          [[ 0.0547, -0.1625,  0.0741],\n",
              "           [-0.0988, -0.0069, -0.1083],\n",
              "           [-0.0329,  0.0222,  0.1556]],\n",
              " \n",
              "          [[-0.1448,  0.1613, -0.1637],\n",
              "           [-0.1208, -0.0160,  0.0410],\n",
              "           [-0.1048, -0.0046,  0.1829]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0151, -0.0389, -0.1083],\n",
              "           [ 0.1750, -0.1128,  0.0114],\n",
              "           [ 0.1843,  0.0651,  0.1501]],\n",
              " \n",
              "          [[ 0.0753,  0.0119, -0.1170],\n",
              "           [ 0.0336,  0.1405, -0.1386],\n",
              "           [ 0.0544, -0.1818,  0.0310]],\n",
              " \n",
              "          [[ 0.1429,  0.1469,  0.1840],\n",
              "           [-0.1144,  0.1144,  0.1420],\n",
              "           [ 0.0030, -0.1034, -0.0022]]],\n",
              " \n",
              " \n",
              "         [[[-0.1025,  0.0967,  0.0599],\n",
              "           [-0.1217, -0.1871, -0.0372],\n",
              "           [-0.0551,  0.1594, -0.0653]],\n",
              " \n",
              "          [[-0.0747,  0.1444, -0.0544],\n",
              "           [ 0.1577,  0.0615,  0.0104],\n",
              "           [ 0.0572, -0.0418, -0.0894]],\n",
              " \n",
              "          [[ 0.0913,  0.1445,  0.1415],\n",
              "           [ 0.0593,  0.1455, -0.0695],\n",
              "           [-0.1610, -0.1110,  0.0363]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0218, -0.1012, -0.0488, -0.0859,  0.1139,  0.0705, -0.0381,  0.1686,\n",
              "          0.0311,  0.0159, -0.0031,  0.0608, -0.1147,  0.1299, -0.0056,  0.0811],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[ 0.0554, -0.0687,  0.0336],\n",
              "           [-0.0773,  0.0418,  0.0628],\n",
              "           [-0.0177,  0.0603,  0.0353]],\n",
              " \n",
              "          [[ 0.0796,  0.0438, -0.0581],\n",
              "           [-0.0285,  0.0359,  0.0486],\n",
              "           [ 0.0806, -0.0503,  0.0651]],\n",
              " \n",
              "          [[-0.0299, -0.0546, -0.0114],\n",
              "           [-0.0372,  0.0628,  0.0278],\n",
              "           [-0.0710, -0.0371, -0.0526]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0530, -0.0090,  0.0456],\n",
              "           [ 0.0465,  0.0704,  0.0208],\n",
              "           [ 0.0438, -0.0284, -0.0591]],\n",
              " \n",
              "          [[ 0.0725, -0.0684,  0.0048],\n",
              "           [ 0.0806,  0.0717, -0.0732],\n",
              "           [-0.0791, -0.0583,  0.0724]],\n",
              " \n",
              "          [[-0.0760,  0.0345, -0.0343],\n",
              "           [-0.0302,  0.0584,  0.0721],\n",
              "           [-0.0692,  0.0489,  0.0244]]],\n",
              " \n",
              " \n",
              "         [[[-0.0532, -0.0153, -0.0241],\n",
              "           [ 0.0253, -0.0356,  0.0340],\n",
              "           [ 0.0332, -0.0774, -0.0040]],\n",
              " \n",
              "          [[-0.0686, -0.0121,  0.0423],\n",
              "           [-0.0627,  0.0274, -0.0181],\n",
              "           [-0.0241, -0.0037, -0.0243]],\n",
              " \n",
              "          [[ 0.0608, -0.0032, -0.0078],\n",
              "           [-0.0038,  0.0119,  0.0363],\n",
              "           [ 0.0447, -0.0377, -0.0012]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0563, -0.0621, -0.0238],\n",
              "           [ 0.0467, -0.0732, -0.0714],\n",
              "           [-0.0291,  0.0297,  0.0480]],\n",
              " \n",
              "          [[ 0.0809, -0.0454, -0.0783],\n",
              "           [-0.0665, -0.0068, -0.0673],\n",
              "           [-0.0603,  0.0136,  0.0096]],\n",
              " \n",
              "          [[-0.0102,  0.0050,  0.0172],\n",
              "           [-0.0747,  0.0210,  0.0706],\n",
              "           [-0.0269,  0.0337, -0.0597]]],\n",
              " \n",
              " \n",
              "         [[[-0.0350,  0.0490, -0.0524],\n",
              "           [ 0.0079, -0.0656, -0.0752],\n",
              "           [-0.0670, -0.0408, -0.0768]],\n",
              " \n",
              "          [[-0.0140, -0.0302,  0.0196],\n",
              "           [ 0.0304,  0.0667, -0.0572],\n",
              "           [-0.0692,  0.0341, -0.0350]],\n",
              " \n",
              "          [[-0.0599,  0.0522,  0.0292],\n",
              "           [ 0.0569, -0.0592, -0.0372],\n",
              "           [-0.0148, -0.0101, -0.0250]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0728,  0.0158,  0.0744],\n",
              "           [ 0.0273, -0.0083, -0.0603],\n",
              "           [ 0.0806, -0.0513,  0.0523]],\n",
              " \n",
              "          [[-0.0471, -0.0328, -0.0320],\n",
              "           [-0.0343, -0.0655, -0.0543],\n",
              "           [-0.0290, -0.0184, -0.0480]],\n",
              " \n",
              "          [[-0.0644, -0.0013,  0.0229],\n",
              "           [-0.0405,  0.0600, -0.0386],\n",
              "           [ 0.0651, -0.0472,  0.0669]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.0706, -0.0501,  0.0085],\n",
              "           [ 0.0252, -0.0687, -0.0651],\n",
              "           [ 0.0006,  0.0602,  0.0765]],\n",
              " \n",
              "          [[-0.0732,  0.0793, -0.0703],\n",
              "           [-0.0560,  0.0088, -0.0609],\n",
              "           [ 0.0184,  0.0315, -0.0006]],\n",
              " \n",
              "          [[ 0.0335, -0.0425, -0.0032],\n",
              "           [ 0.0088, -0.0211,  0.0230],\n",
              "           [ 0.0390,  0.0637, -0.0301]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0331, -0.0584,  0.0644],\n",
              "           [ 0.0387,  0.0796,  0.0735],\n",
              "           [-0.0088,  0.0401,  0.0068]],\n",
              " \n",
              "          [[-0.0819, -0.0755, -0.0558],\n",
              "           [ 0.0389, -0.0676,  0.0737],\n",
              "           [-0.0308, -0.0280,  0.0116]],\n",
              " \n",
              "          [[-0.0336,  0.0635, -0.0646],\n",
              "           [-0.0289,  0.0034, -0.0063],\n",
              "           [ 0.0091,  0.0785,  0.0633]]],\n",
              " \n",
              " \n",
              "         [[[-0.0598,  0.0508, -0.0376],\n",
              "           [ 0.0745,  0.0026,  0.0288],\n",
              "           [-0.0263, -0.0230, -0.0655]],\n",
              " \n",
              "          [[ 0.0606,  0.0598,  0.0625],\n",
              "           [ 0.0411, -0.0313, -0.0703],\n",
              "           [ 0.0152,  0.0770, -0.0217]],\n",
              " \n",
              "          [[ 0.0299, -0.0399,  0.0178],\n",
              "           [-0.0555, -0.0756, -0.0306],\n",
              "           [ 0.0328, -0.0205, -0.0444]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0751,  0.0600,  0.0063],\n",
              "           [ 0.0577, -0.0176,  0.0171],\n",
              "           [ 0.0472, -0.0666,  0.0264]],\n",
              " \n",
              "          [[ 0.0523,  0.0664, -0.0790],\n",
              "           [ 0.0270, -0.0562,  0.0035],\n",
              "           [-0.0317, -0.0186, -0.0724]],\n",
              " \n",
              "          [[ 0.0225,  0.0700, -0.0192],\n",
              "           [ 0.0102,  0.0421, -0.0776],\n",
              "           [ 0.0736, -0.0775, -0.0109]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0350,  0.0110, -0.0536],\n",
              "           [ 0.0550, -0.0267, -0.0376],\n",
              "           [ 0.0606, -0.0813,  0.0626]],\n",
              " \n",
              "          [[ 0.0758, -0.0789,  0.0651],\n",
              "           [-0.0188, -0.0112, -0.0597],\n",
              "           [-0.0446,  0.0514, -0.0567]],\n",
              " \n",
              "          [[-0.0664, -0.0040, -0.0508],\n",
              "           [ 0.0359,  0.0722, -0.0333],\n",
              "           [ 0.0340, -0.0176,  0.0592]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0063, -0.0721, -0.0489],\n",
              "           [-0.0060,  0.0499, -0.0734],\n",
              "           [-0.0676,  0.0255, -0.0109]],\n",
              " \n",
              "          [[ 0.0543, -0.0677,  0.0757],\n",
              "           [-0.0719,  0.0137,  0.0755],\n",
              "           [ 0.0622, -0.0691,  0.0432]],\n",
              " \n",
              "          [[ 0.0148, -0.0685,  0.0440],\n",
              "           [ 0.0481,  0.0704, -0.0800],\n",
              "           [-0.0212,  0.0745,  0.0117]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0747, -0.0277, -0.0122, -0.0647,  0.0138, -0.0447,  0.0748, -0.0239,\n",
              "          0.0289,  0.0520, -0.0464, -0.0779,  0.0781,  0.0309, -0.0041,  0.0485,\n",
              "          0.0439,  0.0401, -0.0255,  0.0423, -0.0106, -0.0184,  0.0404,  0.0808,\n",
              "          0.0342,  0.0371,  0.0561, -0.0624,  0.0774, -0.0030, -0.0651, -0.0342],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-4.7453e-02,  2.4229e-02, -2.0093e-02],\n",
              "           [-1.4385e-02,  2.7373e-02,  5.0653e-02],\n",
              "           [-4.8639e-02,  5.1606e-03, -2.1021e-02]],\n",
              " \n",
              "          [[-3.1653e-02,  3.5350e-02,  9.0350e-03],\n",
              "           [ 3.6975e-02, -2.7447e-02,  3.4229e-03],\n",
              "           [-3.8510e-02, -5.1288e-02,  7.9553e-03]],\n",
              " \n",
              "          [[-4.6117e-02,  3.4095e-02, -2.1430e-02],\n",
              "           [-3.0786e-02,  5.6668e-02,  2.6295e-02],\n",
              "           [ 1.2339e-03,  1.7617e-02,  5.6686e-02]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 2.7171e-02, -5.0606e-02, -5.4290e-02],\n",
              "           [ 2.2663e-02,  1.3762e-02,  1.6183e-02],\n",
              "           [-1.3550e-02, -4.6642e-02,  5.0264e-02]],\n",
              " \n",
              "          [[-6.8176e-03, -3.0538e-02, -3.7470e-02],\n",
              "           [-4.6475e-02,  1.9316e-02,  4.5444e-02],\n",
              "           [-1.8404e-02, -5.6846e-02, -3.9283e-02]],\n",
              " \n",
              "          [[ 8.0831e-03,  4.7195e-02,  2.0821e-02],\n",
              "           [-9.1069e-03,  6.0428e-04,  1.5810e-02],\n",
              "           [ 3.2194e-02,  4.0337e-02,  5.7079e-02]]],\n",
              " \n",
              " \n",
              "         [[[-2.5243e-02,  6.4866e-03, -4.9962e-02],\n",
              "           [-3.7990e-02,  4.1773e-02,  3.4366e-02],\n",
              "           [-1.4263e-02,  4.2969e-02, -8.1751e-04]],\n",
              " \n",
              "          [[ 3.1011e-02, -2.1470e-02, -2.0258e-02],\n",
              "           [ 2.7114e-02, -5.5471e-02, -3.4811e-02],\n",
              "           [-3.2672e-02, -1.3692e-03, -1.1403e-02]],\n",
              " \n",
              "          [[ 4.7492e-02, -5.8366e-03, -2.6119e-02],\n",
              "           [-1.4166e-02,  2.1891e-02,  3.4884e-02],\n",
              "           [ 3.4032e-02,  2.0087e-02,  4.3332e-02]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-3.6664e-02, -9.3027e-03, -1.8519e-02],\n",
              "           [ 2.0255e-02,  4.6148e-02, -1.7495e-02],\n",
              "           [-1.5234e-02,  5.4549e-02, -1.4858e-02]],\n",
              " \n",
              "          [[ 4.3445e-02, -2.7960e-03, -3.0639e-02],\n",
              "           [-4.7479e-02, -1.3727e-02,  3.7195e-02],\n",
              "           [-1.5429e-02,  4.6548e-02, -8.1356e-03]],\n",
              " \n",
              "          [[ 2.2977e-02, -6.8094e-03, -1.9872e-02],\n",
              "           [-1.0059e-03,  2.3960e-02,  7.4782e-03],\n",
              "           [ 4.6793e-02, -4.2716e-02,  4.6734e-02]]],\n",
              " \n",
              " \n",
              "         [[[ 1.6767e-02, -5.6583e-02,  3.7780e-02],\n",
              "           [-2.0954e-02,  2.4694e-02, -5.8331e-02],\n",
              "           [ 4.5325e-02, -4.8942e-02,  2.0320e-02]],\n",
              " \n",
              "          [[ 5.4281e-02, -2.1358e-02, -3.7529e-02],\n",
              "           [-5.0897e-02,  1.7012e-03, -3.5080e-02],\n",
              "           [ 5.1951e-02, -1.8872e-02,  4.8853e-02]],\n",
              " \n",
              "          [[-2.2164e-02, -9.6976e-04, -3.8154e-02],\n",
              "           [ 4.5946e-03,  5.1708e-02,  4.7799e-02],\n",
              "           [ 9.0023e-03,  3.6774e-02,  5.8359e-02]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 2.6068e-02,  5.0694e-02, -5.1292e-03],\n",
              "           [ 3.1893e-02,  2.1092e-02,  3.0562e-02],\n",
              "           [-2.4923e-02,  3.6524e-02,  6.0913e-04]],\n",
              " \n",
              "          [[ 1.1039e-02, -5.2850e-02, -3.1778e-03],\n",
              "           [ 5.7197e-02,  4.6549e-02,  2.6089e-03],\n",
              "           [ 3.5491e-02, -2.5245e-02,  3.9572e-02]],\n",
              " \n",
              "          [[ 2.7781e-02,  5.6144e-02,  1.6970e-02],\n",
              "           [-7.5549e-03, -3.5237e-02, -1.5559e-02],\n",
              "           [ 1.8991e-02, -3.3403e-02,  1.8202e-02]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[ 3.0559e-02, -1.2421e-02, -2.4819e-02],\n",
              "           [-1.1110e-02,  4.0363e-02, -5.3799e-02],\n",
              "           [-2.7617e-02, -5.8144e-03,  2.4374e-02]],\n",
              " \n",
              "          [[-5.3072e-03, -5.5907e-02, -1.9940e-02],\n",
              "           [-4.0904e-02,  5.1077e-03, -4.0401e-02],\n",
              "           [ 1.5659e-02, -4.2862e-02,  2.6621e-02]],\n",
              " \n",
              "          [[-5.6405e-02, -1.5857e-02, -3.1346e-02],\n",
              "           [-2.8343e-02,  4.6729e-02,  4.9110e-02],\n",
              "           [-6.4586e-03,  3.9238e-02, -5.4160e-02]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-2.7353e-02,  5.6375e-02,  2.5529e-02],\n",
              "           [-1.8924e-02, -1.4386e-02, -8.9892e-03],\n",
              "           [-4.2693e-02,  2.2109e-02, -2.8145e-02]],\n",
              " \n",
              "          [[-1.7671e-02, -5.8380e-02, -4.2205e-02],\n",
              "           [ 4.4797e-02, -3.9384e-02,  3.1444e-02],\n",
              "           [ 6.5001e-03, -1.5932e-03,  4.7893e-02]],\n",
              " \n",
              "          [[ 6.7753e-03, -3.4396e-02, -2.8886e-02],\n",
              "           [-3.2368e-02, -2.4898e-02,  1.8440e-02],\n",
              "           [ 4.3845e-02,  1.4174e-02, -4.2359e-02]]],\n",
              " \n",
              " \n",
              "         [[[-4.1471e-02,  3.0002e-02,  5.4239e-02],\n",
              "           [ 4.4824e-02, -4.2258e-02, -6.8418e-03],\n",
              "           [ 8.7469e-05,  4.1904e-02,  2.1761e-03]],\n",
              " \n",
              "          [[-3.4578e-02,  5.5111e-02,  5.6514e-02],\n",
              "           [-5.1636e-02, -4.5032e-02,  2.9944e-02],\n",
              "           [ 3.0519e-02, -3.8980e-02, -1.9659e-02]],\n",
              " \n",
              "          [[ 5.5015e-02,  1.0481e-02,  2.1999e-02],\n",
              "           [ 4.3028e-02,  3.2460e-03,  4.9112e-02],\n",
              "           [-5.4375e-02,  4.9439e-02,  2.5235e-02]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-2.6124e-02, -5.3107e-02,  7.4496e-03],\n",
              "           [-5.1209e-02,  1.4578e-02,  3.3717e-02],\n",
              "           [ 4.2264e-02, -4.5575e-02,  8.7965e-03]],\n",
              " \n",
              "          [[ 4.9400e-03,  3.9820e-02, -4.7773e-03],\n",
              "           [-3.4982e-02,  2.0225e-02,  3.8449e-02],\n",
              "           [ 3.9966e-02, -5.8341e-03,  5.2605e-02]],\n",
              " \n",
              "          [[-5.3453e-02, -4.4977e-02, -1.8156e-02],\n",
              "           [-1.8601e-02,  4.9138e-02,  2.4754e-02],\n",
              "           [-9.5287e-04, -5.4990e-04, -4.3951e-02]]],\n",
              " \n",
              " \n",
              "         [[[-4.4907e-02,  3.4276e-02, -3.2040e-03],\n",
              "           [-3.0165e-02, -7.2221e-03, -2.9314e-02],\n",
              "           [-2.3631e-02, -1.4687e-02, -2.3182e-03]],\n",
              " \n",
              "          [[ 2.7134e-03, -5.2207e-02, -1.9164e-02],\n",
              "           [-1.4225e-02,  2.4655e-02, -4.0301e-02],\n",
              "           [ 2.1161e-02, -2.5858e-02,  5.3781e-02]],\n",
              " \n",
              "          [[-4.3387e-02, -4.9354e-02, -4.0112e-03],\n",
              "           [-1.8297e-02, -2.9544e-02,  2.7406e-02],\n",
              "           [-4.3151e-02,  3.1620e-02, -2.4530e-02]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 5.8121e-02, -5.4878e-02,  4.9356e-02],\n",
              "           [-4.0476e-02,  5.3916e-03, -5.4554e-02],\n",
              "           [ 1.1135e-02, -7.4286e-03, -2.0939e-02]],\n",
              " \n",
              "          [[-3.5731e-02,  1.2974e-02,  2.5482e-02],\n",
              "           [-1.2762e-02,  3.6918e-02, -8.5188e-03],\n",
              "           [ 1.7857e-02, -1.8488e-02,  1.4129e-02]],\n",
              " \n",
              "          [[-5.3166e-02, -3.4310e-02, -2.5290e-03],\n",
              "           [ 2.0598e-02, -4.5313e-02, -9.9873e-04],\n",
              "           [ 1.1654e-02,  4.0724e-02,  4.5328e-02]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0231,  0.0475,  0.0365, -0.0099,  0.0164, -0.0197, -0.0002,  0.0289,\n",
              "          0.0338,  0.0290, -0.0270,  0.0424, -0.0397, -0.0263, -0.0433, -0.0102,\n",
              "         -0.0553,  0.0146,  0.0329,  0.0524,  0.0170,  0.0249, -0.0523,  0.0216,\n",
              "         -0.0380, -0.0208,  0.0518, -0.0222, -0.0266,  0.0017, -0.0025, -0.0388,\n",
              "         -0.0065,  0.0241,  0.0275, -0.0337,  0.0371,  0.0370,  0.0519,  0.0361,\n",
              "         -0.0205, -0.0314,  0.0316,  0.0536,  0.0391, -0.0311, -0.0527, -0.0017,\n",
              "          0.0175, -0.0067, -0.0234, -0.0376, -0.0509, -0.0274,  0.0395,  0.0482,\n",
              "         -0.0425,  0.0237,  0.0435,  0.0367, -0.0453, -0.0416,  0.0284,  0.0395],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[ 0.0194,  0.0132,  0.0112],\n",
              "           [ 0.0082, -0.0198,  0.0208],\n",
              "           [-0.0119, -0.0302,  0.0196]],\n",
              " \n",
              "          [[-0.0124,  0.0400,  0.0117],\n",
              "           [ 0.0027, -0.0313, -0.0390],\n",
              "           [-0.0017, -0.0233,  0.0191]],\n",
              " \n",
              "          [[-0.0402, -0.0366, -0.0345],\n",
              "           [ 0.0276, -0.0127, -0.0382],\n",
              "           [ 0.0397, -0.0362, -0.0259]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0253, -0.0131, -0.0280],\n",
              "           [-0.0138,  0.0226,  0.0273],\n",
              "           [-0.0316,  0.0369,  0.0034]],\n",
              " \n",
              "          [[-0.0089,  0.0227,  0.0306],\n",
              "           [-0.0042,  0.0116,  0.0311],\n",
              "           [-0.0375,  0.0270,  0.0183]],\n",
              " \n",
              "          [[ 0.0190, -0.0280, -0.0248],\n",
              "           [-0.0379, -0.0005, -0.0007],\n",
              "           [ 0.0164,  0.0141, -0.0145]]],\n",
              " \n",
              " \n",
              "         [[[-0.0070, -0.0168, -0.0016],\n",
              "           [-0.0312, -0.0340,  0.0128],\n",
              "           [-0.0165,  0.0350, -0.0322]],\n",
              " \n",
              "          [[ 0.0220,  0.0151, -0.0114],\n",
              "           [ 0.0323,  0.0320, -0.0254],\n",
              "           [ 0.0093, -0.0059, -0.0020]],\n",
              " \n",
              "          [[ 0.0333, -0.0313,  0.0261],\n",
              "           [-0.0130,  0.0293,  0.0284],\n",
              "           [ 0.0041, -0.0093, -0.0238]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0090,  0.0381,  0.0159],\n",
              "           [ 0.0267,  0.0237,  0.0375],\n",
              "           [-0.0243, -0.0308,  0.0308]],\n",
              " \n",
              "          [[ 0.0160,  0.0155, -0.0093],\n",
              "           [ 0.0101, -0.0081, -0.0127],\n",
              "           [ 0.0366, -0.0146,  0.0027]],\n",
              " \n",
              "          [[-0.0120,  0.0231, -0.0063],\n",
              "           [-0.0132,  0.0158,  0.0152],\n",
              "           [ 0.0009,  0.0247,  0.0101]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0134, -0.0371, -0.0271],\n",
              "           [-0.0346, -0.0247,  0.0118],\n",
              "           [-0.0095, -0.0149,  0.0371]],\n",
              " \n",
              "          [[ 0.0137,  0.0335,  0.0322],\n",
              "           [ 0.0131,  0.0164,  0.0197],\n",
              "           [ 0.0188,  0.0191,  0.0226]],\n",
              " \n",
              "          [[ 0.0159,  0.0351,  0.0002],\n",
              "           [-0.0008, -0.0257, -0.0027],\n",
              "           [-0.0382,  0.0297,  0.0395]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0205, -0.0275, -0.0372],\n",
              "           [-0.0188, -0.0072, -0.0074],\n",
              "           [ 0.0378,  0.0371, -0.0225]],\n",
              " \n",
              "          [[ 0.0212,  0.0186, -0.0131],\n",
              "           [-0.0229, -0.0277, -0.0223],\n",
              "           [-0.0112, -0.0305, -0.0276]],\n",
              " \n",
              "          [[ 0.0004, -0.0240, -0.0288],\n",
              "           [ 0.0035,  0.0229, -0.0151],\n",
              "           [-0.0344, -0.0193,  0.0084]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.0054,  0.0381,  0.0254],\n",
              "           [-0.0231,  0.0367, -0.0303],\n",
              "           [-0.0293, -0.0309,  0.0321]],\n",
              " \n",
              "          [[ 0.0306, -0.0197, -0.0307],\n",
              "           [-0.0314, -0.0276,  0.0061],\n",
              "           [-0.0411,  0.0315,  0.0076]],\n",
              " \n",
              "          [[-0.0197,  0.0061,  0.0002],\n",
              "           [ 0.0084, -0.0159, -0.0073],\n",
              "           [-0.0052, -0.0327, -0.0189]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[-0.0183, -0.0080, -0.0201],\n",
              "           [ 0.0173,  0.0130,  0.0031],\n",
              "           [-0.0128, -0.0408, -0.0175]],\n",
              " \n",
              "          [[-0.0025,  0.0059,  0.0136],\n",
              "           [ 0.0347,  0.0196, -0.0229],\n",
              "           [ 0.0294, -0.0054, -0.0177]],\n",
              " \n",
              "          [[ 0.0295,  0.0206,  0.0032],\n",
              "           [ 0.0406, -0.0332, -0.0050],\n",
              "           [-0.0271, -0.0381,  0.0355]]],\n",
              " \n",
              " \n",
              "         [[[-0.0234, -0.0112, -0.0067],\n",
              "           [ 0.0103, -0.0355, -0.0365],\n",
              "           [-0.0036, -0.0416,  0.0363]],\n",
              " \n",
              "          [[ 0.0146, -0.0336,  0.0340],\n",
              "           [-0.0175,  0.0006,  0.0107],\n",
              "           [-0.0304, -0.0315, -0.0249]],\n",
              " \n",
              "          [[-0.0179,  0.0134,  0.0058],\n",
              "           [ 0.0007,  0.0224, -0.0359],\n",
              "           [ 0.0056,  0.0212, -0.0396]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0103, -0.0276,  0.0151],\n",
              "           [-0.0021, -0.0292,  0.0268],\n",
              "           [ 0.0366,  0.0003,  0.0360]],\n",
              " \n",
              "          [[-0.0104, -0.0336,  0.0012],\n",
              "           [-0.0322,  0.0101,  0.0299],\n",
              "           [-0.0263, -0.0117,  0.0258]],\n",
              " \n",
              "          [[-0.0251, -0.0115,  0.0191],\n",
              "           [ 0.0054, -0.0243,  0.0208],\n",
              "           [-0.0358, -0.0195, -0.0339]]],\n",
              " \n",
              " \n",
              "         [[[-0.0369,  0.0029, -0.0315],\n",
              "           [-0.0059, -0.0391,  0.0318],\n",
              "           [-0.0339, -0.0371, -0.0306]],\n",
              " \n",
              "          [[ 0.0208,  0.0022, -0.0288],\n",
              "           [ 0.0107,  0.0281,  0.0090],\n",
              "           [ 0.0193,  0.0115, -0.0029]],\n",
              " \n",
              "          [[-0.0282, -0.0056, -0.0229],\n",
              "           [ 0.0021,  0.0063, -0.0267],\n",
              "           [-0.0027,  0.0081,  0.0337]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 0.0401,  0.0102, -0.0157],\n",
              "           [ 0.0066,  0.0085,  0.0393],\n",
              "           [-0.0263, -0.0177,  0.0288]],\n",
              " \n",
              "          [[-0.0216, -0.0079,  0.0314],\n",
              "           [ 0.0298,  0.0388,  0.0044],\n",
              "           [ 0.0160,  0.0244, -0.0363]],\n",
              " \n",
              "          [[ 0.0345, -0.0191, -0.0297],\n",
              "           [ 0.0243,  0.0123,  0.0011],\n",
              "           [ 0.0073, -0.0132,  0.0401]]]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0390, -0.0410, -0.0308,  0.0117,  0.0062, -0.0148, -0.0069,  0.0378,\n",
              "         -0.0408,  0.0023, -0.0141, -0.0119,  0.0264, -0.0366,  0.0335,  0.0152,\n",
              "         -0.0321, -0.0218, -0.0405,  0.0276, -0.0369, -0.0380,  0.0358, -0.0306,\n",
              "         -0.0308,  0.0295,  0.0220, -0.0301, -0.0045, -0.0400,  0.0197,  0.0359,\n",
              "         -0.0032, -0.0255,  0.0034, -0.0021, -0.0220, -0.0337, -0.0085,  0.0008,\n",
              "         -0.0066,  0.0242, -0.0213, -0.0177, -0.0069,  0.0411,  0.0068, -0.0142,\n",
              "          0.0055, -0.0016,  0.0173,  0.0396,  0.0134, -0.0062,  0.0203,  0.0334,\n",
              "          0.0166, -0.0234, -0.0287, -0.0175, -0.0401,  0.0039, -0.0023,  0.0211,\n",
              "          0.0320,  0.0132,  0.0360, -0.0036,  0.0016, -0.0280, -0.0353, -0.0336,\n",
              "          0.0062,  0.0319, -0.0177, -0.0415,  0.0265, -0.0408,  0.0241,  0.0003,\n",
              "          0.0058,  0.0201, -0.0252, -0.0223, -0.0291, -0.0248, -0.0178,  0.0401,\n",
              "          0.0387,  0.0057, -0.0373, -0.0233,  0.0096,  0.0057,  0.0387, -0.0039,\n",
              "         -0.0148, -0.0084,  0.0258, -0.0003,  0.0278, -0.0340, -0.0065,  0.0148,\n",
              "          0.0077,  0.0361,  0.0214,  0.0088, -0.0195, -0.0025,  0.0386,  0.0333,\n",
              "         -0.0040, -0.0212,  0.0172, -0.0070,  0.0142,  0.0413, -0.0042, -0.0347,\n",
              "          0.0199,  0.0156, -0.0272, -0.0243,  0.0266,  0.0064,  0.0406, -0.0258],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0101,  0.0073, -0.0358,  ...,  0.0184,  0.0291, -0.0303],\n",
              "         [ 0.0048,  0.0253,  0.0377,  ..., -0.0044, -0.0084, -0.0127],\n",
              "         [-0.0214,  0.0057,  0.0251,  ...,  0.0346, -0.0277,  0.0016],\n",
              "         ...,\n",
              "         [-0.0364,  0.0329, -0.0115,  ..., -0.0295,  0.0060, -0.0385],\n",
              "         [-0.0138, -0.0035, -0.0240,  ...,  0.0276, -0.0256, -0.0092],\n",
              "         [ 0.0314,  0.0409, -0.0328,  ...,  0.0241, -0.0323,  0.0273]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 1.7719e-02,  1.2684e-02, -2.1632e-02,  2.2808e-03, -1.3462e-02,\n",
              "         -8.7785e-03,  3.8958e-02,  2.7854e-02, -1.7739e-02, -3.4401e-03,\n",
              "         -1.6681e-02,  2.8000e-02, -6.2491e-03,  2.6412e-02,  7.9039e-03,\n",
              "          1.9323e-02,  9.5547e-03,  3.1077e-02, -2.4038e-02,  2.8729e-02,\n",
              "         -2.4226e-02,  3.4809e-02, -1.2549e-02, -7.5717e-04, -8.8110e-03,\n",
              "          2.2277e-02, -2.7338e-03,  2.2251e-02,  3.4580e-03, -4.3685e-02,\n",
              "          2.1239e-02,  3.0894e-02,  3.7584e-02, -1.2112e-02, -3.4517e-02,\n",
              "         -1.2210e-02, -6.5855e-03,  1.2433e-02, -2.0604e-02,  4.0656e-02,\n",
              "         -3.9080e-02,  4.5879e-03, -2.2266e-02, -4.2809e-02,  4.3497e-02,\n",
              "          1.8572e-02, -3.8832e-02, -1.8561e-02,  8.7439e-03,  1.7602e-02,\n",
              "         -3.3467e-02, -4.0646e-02, -3.8305e-02,  7.8156e-03,  2.2078e-02,\n",
              "         -9.8839e-03, -6.2304e-03,  1.7884e-02,  3.0550e-03, -4.5740e-03,\n",
              "          1.4722e-02, -1.2675e-04,  4.3323e-02,  4.1875e-02, -2.7717e-02,\n",
              "          7.6334e-03, -3.0511e-02, -1.3688e-03, -3.5819e-02, -4.2975e-02,\n",
              "          1.7215e-02, -1.4703e-02,  1.2405e-02,  9.2442e-03,  1.7228e-02,\n",
              "         -3.6093e-02, -1.2223e-02,  4.2631e-02,  3.8960e-02, -4.1981e-02,\n",
              "         -5.9643e-03, -1.5717e-02,  2.7831e-02,  1.7259e-02,  1.5901e-02,\n",
              "          7.6440e-03,  2.6136e-02, -2.0706e-02,  3.3618e-02,  5.2003e-03,\n",
              "          1.4889e-02, -3.5736e-02,  1.3525e-02, -3.8396e-02,  2.4936e-02,\n",
              "          3.0691e-02, -2.0278e-02,  2.1109e-02, -3.9528e-02, -3.6745e-02,\n",
              "         -6.3705e-03,  2.8639e-02, -9.3822e-04, -1.3456e-02,  1.4157e-02,\n",
              "         -3.5401e-02, -3.9583e-02,  1.7427e-02,  1.2680e-02,  2.0646e-02,\n",
              "          2.7302e-02, -2.6957e-02, -2.3645e-02,  2.4877e-02,  2.8681e-02,\n",
              "          1.3029e-02, -2.5761e-02,  3.2437e-02, -1.1783e-03,  3.1715e-02,\n",
              "         -4.1550e-02,  2.8153e-03,  2.8549e-02, -3.0135e-02,  3.3587e-02,\n",
              "         -4.1045e-02,  1.5636e-02, -7.1164e-03, -1.3836e-02,  2.2658e-02,\n",
              "         -2.7173e-02, -4.0388e-02,  1.3139e-02,  2.3906e-02,  2.0136e-02,\n",
              "          8.5668e-03,  3.8803e-02, -3.5824e-02, -1.3663e-02, -4.1038e-02,\n",
              "          1.1993e-02, -2.3173e-02, -3.7516e-02, -1.1754e-02, -6.4767e-03,\n",
              "         -4.6142e-03, -3.0058e-02,  1.2488e-03,  3.3659e-02, -5.6562e-03,\n",
              "          1.9200e-02, -3.8635e-02, -1.3760e-02,  1.2255e-02, -3.5361e-02,\n",
              "         -3.1204e-02, -2.4142e-02, -4.1223e-02, -2.9772e-02, -8.8530e-03,\n",
              "          4.1727e-03, -4.3859e-02,  6.5205e-03,  1.2080e-02, -1.2422e-02,\n",
              "          2.2883e-02, -1.4173e-02, -2.5287e-02, -2.7536e-02,  8.9917e-03,\n",
              "         -4.1362e-02,  4.0313e-02,  3.3625e-02,  3.8982e-03, -9.0570e-03,\n",
              "         -3.1680e-02, -3.5569e-02,  1.4442e-02,  6.9970e-04, -2.8314e-02,\n",
              "         -1.9350e-02, -4.3630e-02, -3.9253e-02,  2.1965e-02,  2.1319e-02,\n",
              "         -2.3119e-02, -2.9146e-02,  3.6776e-02, -3.2648e-02,  3.4778e-02,\n",
              "          3.4027e-02, -1.6594e-02,  1.3273e-02,  1.0064e-02,  9.3960e-03,\n",
              "          3.0166e-02,  1.5440e-02,  5.8603e-03, -7.2676e-03, -2.1983e-02,\n",
              "          3.6126e-02, -2.2746e-02,  4.2589e-02, -3.9049e-05,  3.5446e-02,\n",
              "          8.1339e-03, -2.1847e-02,  1.8311e-02,  2.8203e-02, -9.6216e-03,\n",
              "          3.1975e-02,  8.3343e-03, -2.5885e-02, -2.6620e-02,  1.5508e-02,\n",
              "         -2.7293e-02,  7.8635e-03, -2.1256e-02,  9.9609e-03, -2.1796e-02,\n",
              "         -2.4820e-03, -3.1690e-02,  2.4741e-02, -2.8597e-02, -2.9998e-02,\n",
              "         -3.9568e-02,  1.2540e-02, -7.6680e-03,  3.1808e-02,  6.6292e-03,\n",
              "          1.6905e-02,  4.1081e-02, -8.5437e-03, -3.7755e-02, -2.5032e-02,\n",
              "          2.8199e-02,  1.7478e-02, -1.4804e-02,  5.2891e-03,  1.4923e-04,\n",
              "         -2.6158e-02,  3.4501e-02,  5.0177e-03, -6.1384e-04, -2.5392e-02,\n",
              "         -3.8643e-02,  1.1265e-02, -3.8289e-02,  2.4593e-02, -2.3438e-02,\n",
              "          1.6589e-02,  2.0349e-02,  3.1783e-02, -7.6343e-03,  1.9777e-02,\n",
              "         -8.4687e-03, -2.6993e-02,  9.1431e-03,  9.4282e-03,  1.6551e-02,\n",
              "          3.4700e-02, -9.1547e-03,  1.0624e-03, -3.6695e-02, -9.4022e-03,\n",
              "         -3.0643e-02,  3.0818e-02,  3.3941e-02,  3.2605e-02, -3.0220e-02,\n",
              "         -6.6009e-03, -1.2586e-02,  1.5828e-02, -1.3603e-02,  2.7035e-02,\n",
              "          3.1276e-03, -7.7983e-03,  2.0559e-02,  2.9151e-02,  3.7154e-02,\n",
              "          2.9734e-02, -1.6063e-02, -3.1397e-02,  2.9053e-02, -2.3484e-04,\n",
              "         -1.8815e-02,  2.4712e-02,  8.6699e-03,  1.1793e-02, -4.1730e-02,\n",
              "         -4.0877e-02, -1.4727e-02,  1.7899e-02,  4.1867e-02, -2.4305e-02,\n",
              "          2.1204e-02, -7.6972e-03, -1.1613e-02,  2.6747e-02,  1.1536e-02,\n",
              "         -3.5998e-03,  2.8680e-02, -4.1980e-03, -2.2051e-02,  1.5297e-02,\n",
              "         -1.1915e-02,  2.5025e-02,  4.0263e-02,  1.2772e-03,  9.7004e-03,\n",
              "         -4.0961e-02, -3.7762e-02, -3.4600e-02, -1.2764e-02,  8.0238e-03,\n",
              "         -6.7609e-03,  2.4426e-03,  1.1007e-02, -1.8179e-02, -1.8904e-03,\n",
              "          3.6171e-02,  3.0921e-02,  4.2582e-02, -8.2683e-03,  7.6376e-03,\n",
              "         -4.3070e-02, -2.7727e-02,  4.2728e-02, -4.4176e-02, -2.0695e-02,\n",
              "          2.6299e-02, -1.6031e-02, -1.8332e-02, -3.4112e-02,  1.3478e-02,\n",
              "          1.1692e-02, -1.0740e-02, -2.6321e-02, -1.6643e-02,  1.0418e-02,\n",
              "         -3.1993e-02, -4.2946e-02,  2.1969e-02, -1.5705e-02,  1.9174e-02,\n",
              "         -4.7594e-03, -3.8023e-02,  3.6038e-02, -4.2090e-02, -4.4234e-03,\n",
              "         -3.8400e-02,  4.2570e-02,  2.2700e-02,  4.2072e-02,  1.6245e-02,\n",
              "         -3.3933e-02, -3.6245e-03, -1.1645e-02, -3.1034e-02,  1.7610e-03,\n",
              "          2.1981e-02,  6.8498e-03,  3.6324e-02,  2.6834e-02,  4.2637e-02,\n",
              "         -2.2277e-03,  2.4056e-02, -3.1526e-02,  2.3578e-02,  9.4168e-03,\n",
              "         -3.2085e-02,  1.3542e-02, -2.9383e-02,  2.3868e-03, -3.1450e-02,\n",
              "         -3.0772e-02, -3.8483e-02, -3.6115e-02,  2.3703e-03,  1.8811e-02,\n",
              "         -1.9966e-03,  3.8281e-02, -2.1688e-03, -2.9472e-02, -7.5573e-03,\n",
              "          2.3079e-02,  1.9338e-02,  1.5900e-02,  8.1613e-03,  2.8882e-02,\n",
              "         -2.7584e-03,  1.6142e-02, -1.9901e-02, -4.0279e-02,  3.2684e-02,\n",
              "          2.0671e-02, -2.0707e-02,  1.6300e-02, -3.5406e-02, -2.0309e-02,\n",
              "          2.4522e-02,  9.1410e-03,  3.0090e-02, -3.6491e-02,  3.1254e-02,\n",
              "         -1.3477e-02, -4.2880e-02,  3.3600e-02, -2.7033e-02, -3.5321e-02,\n",
              "          1.7993e-02,  2.8272e-02, -3.0883e-02,  1.3229e-02,  6.6389e-03,\n",
              "          3.6055e-02, -6.7464e-04,  8.3346e-03,  7.7316e-03,  7.5641e-03,\n",
              "         -4.1676e-03, -4.9829e-04,  4.0602e-02,  3.4220e-02, -2.8071e-02,\n",
              "          1.1794e-02,  5.0700e-03, -1.6592e-02,  1.7997e-02,  1.3172e-02,\n",
              "          3.5503e-02, -2.0860e-02, -3.6992e-02, -1.8493e-02, -3.1557e-03,\n",
              "         -1.3904e-02,  2.4232e-02,  2.4062e-02, -1.7930e-02, -8.4106e-03,\n",
              "          4.1017e-02,  1.4819e-02, -2.7621e-02, -2.5586e-03,  4.5199e-03,\n",
              "          3.5807e-02, -3.1121e-02,  3.8504e-03, -3.3294e-02,  1.0135e-02,\n",
              "          2.7734e-02, -4.2915e-03,  9.1856e-03,  3.1463e-02, -2.4891e-02,\n",
              "         -8.0943e-03,  2.1721e-02, -3.7190e-02, -2.6043e-02,  2.5504e-02,\n",
              "          2.7814e-02,  1.8100e-02, -1.9003e-02,  2.6132e-03, -2.5465e-03,\n",
              "         -3.2931e-02, -4.2796e-02, -2.8848e-02, -3.8476e-02, -2.3627e-02,\n",
              "         -3.7941e-02,  3.3110e-02,  1.0247e-02, -1.0949e-02, -1.9130e-02,\n",
              "          3.4470e-02,  3.8184e-02, -4.4092e-02, -2.8642e-02, -2.9506e-02,\n",
              "          5.0877e-03, -3.1948e-02, -1.3029e-04,  2.1187e-02, -2.3660e-02,\n",
              "         -1.1109e-02, -1.4753e-02,  1.0491e-02,  9.5115e-03, -3.5774e-02,\n",
              "          1.3602e-02,  2.5023e-03, -2.0220e-02,  2.5251e-02, -4.3243e-03,\n",
              "          7.1632e-03, -3.6906e-02, -8.5608e-03,  3.0570e-02,  3.1831e-02,\n",
              "          3.9521e-03,  1.1831e-02,  1.0029e-02,  1.2119e-02, -3.9049e-03,\n",
              "         -1.7826e-02,  3.7280e-02, -2.4185e-02, -2.4152e-02,  3.4361e-02,\n",
              "          2.2563e-02,  1.9280e-02], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0346,  0.0188,  0.0333,  ..., -0.0263, -0.0304, -0.0317],\n",
              "         [ 0.0203, -0.0056,  0.0332,  ...,  0.0246, -0.0429, -0.0236],\n",
              "         [-0.0412, -0.0157,  0.0311,  ..., -0.0071,  0.0267, -0.0031],\n",
              "         ...,\n",
              "         [-0.0319,  0.0166,  0.0100,  ...,  0.0346,  0.0421, -0.0014],\n",
              "         [ 0.0124,  0.0323, -0.0206,  ...,  0.0228, -0.0183,  0.0180],\n",
              "         [ 0.0294,  0.0098, -0.0365,  ...,  0.0162,  0.0387, -0.0311]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0277, -0.0016,  0.0041, -0.0054, -0.0110, -0.0357,  0.0139, -0.0057,\n",
              "          0.0375, -0.0053, -0.0020, -0.0129,  0.0441, -0.0364,  0.0302,  0.0367,\n",
              "         -0.0304,  0.0100, -0.0189,  0.0004,  0.0115, -0.0271, -0.0248, -0.0364,\n",
              "         -0.0323,  0.0233,  0.0323,  0.0356, -0.0348,  0.0264,  0.0245, -0.0418,\n",
              "         -0.0157,  0.0073, -0.0334, -0.0184,  0.0047,  0.0020,  0.0218,  0.0137,\n",
              "         -0.0266,  0.0176,  0.0223,  0.0436,  0.0388, -0.0081, -0.0358, -0.0037,\n",
              "         -0.0126,  0.0381, -0.0090,  0.0064, -0.0267, -0.0338, -0.0148,  0.0024,\n",
              "          0.0096,  0.0217, -0.0158,  0.0407,  0.0336, -0.0230, -0.0156, -0.0431,\n",
              "         -0.0161,  0.0171,  0.0107,  0.0266,  0.0035, -0.0281,  0.0350,  0.0205,\n",
              "          0.0361, -0.0397,  0.0439,  0.0196,  0.0424, -0.0370,  0.0381, -0.0257,\n",
              "          0.0281, -0.0242, -0.0426,  0.0387, -0.0367, -0.0372, -0.0397,  0.0242,\n",
              "          0.0359, -0.0134, -0.0076,  0.0371, -0.0165,  0.0386, -0.0325, -0.0074,\n",
              "          0.0137,  0.0181,  0.0188,  0.0193,  0.0105, -0.0007, -0.0417,  0.0223,\n",
              "          0.0340,  0.0247, -0.0344, -0.0101,  0.0136,  0.0121,  0.0398, -0.0239,\n",
              "          0.0068,  0.0047, -0.0104, -0.0062, -0.0030, -0.0172, -0.0078,  0.0012,\n",
              "          0.0143,  0.0161, -0.0403, -0.0232, -0.0133, -0.0133, -0.0374, -0.0210,\n",
              "          0.0276,  0.0382, -0.0337,  0.0281, -0.0211,  0.0297,  0.0306, -0.0071,\n",
              "         -0.0183,  0.0048,  0.0294, -0.0017, -0.0371,  0.0272,  0.0222,  0.0095,\n",
              "         -0.0414,  0.0359,  0.0162,  0.0264,  0.0306, -0.0098,  0.0099,  0.0394,\n",
              "         -0.0233,  0.0193,  0.0366,  0.0285, -0.0391,  0.0341,  0.0322,  0.0383,\n",
              "          0.0101,  0.0320, -0.0112, -0.0016, -0.0009, -0.0371, -0.0230, -0.0137,\n",
              "         -0.0089,  0.0110,  0.0292, -0.0187,  0.0377,  0.0430, -0.0197,  0.0181,\n",
              "          0.0129,  0.0102,  0.0304, -0.0109, -0.0295,  0.0349, -0.0031,  0.0065,\n",
              "          0.0378, -0.0069, -0.0288, -0.0058,  0.0348,  0.0388,  0.0012,  0.0107,\n",
              "         -0.0391,  0.0247,  0.0352, -0.0057, -0.0168,  0.0316, -0.0143, -0.0374,\n",
              "          0.0223, -0.0363,  0.0247,  0.0321,  0.0170, -0.0205, -0.0188,  0.0149,\n",
              "          0.0097, -0.0247,  0.0107, -0.0337, -0.0382, -0.0013,  0.0395,  0.0265,\n",
              "         -0.0031,  0.0082, -0.0065,  0.0100,  0.0276,  0.0127,  0.0108, -0.0416,\n",
              "         -0.0398, -0.0362, -0.0363, -0.0324, -0.0234, -0.0181,  0.0209,  0.0044,\n",
              "         -0.0069, -0.0303, -0.0373,  0.0217,  0.0329,  0.0069,  0.0197,  0.0051,\n",
              "         -0.0148, -0.0071, -0.0435, -0.0197,  0.0166, -0.0076,  0.0418,  0.0412,\n",
              "          0.0191, -0.0111, -0.0103,  0.0198, -0.0422,  0.0235, -0.0281,  0.0391],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0151,  0.0087,  0.0209,  ..., -0.0490,  0.0253,  0.0387],\n",
              "         [-0.0442,  0.0508,  0.0056,  ..., -0.0505,  0.0324,  0.0171],\n",
              "         [-0.0568, -0.0559,  0.0267,  ...,  0.0447,  0.0396,  0.0406],\n",
              "         ...,\n",
              "         [-0.0355,  0.0024,  0.0406,  ..., -0.0226,  0.0136, -0.0082],\n",
              "         [-0.0461,  0.0205,  0.0411,  ..., -0.0139,  0.0462,  0.0296],\n",
              "         [-0.0334,  0.0174,  0.0610,  ...,  0.0085, -0.0095,  0.0505]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0308, -0.0082,  0.0026,  0.0080,  0.0431, -0.0533,  0.0453,  0.0274,\n",
              "          0.0096,  0.0591,  0.0525, -0.0491, -0.0206, -0.0115,  0.0051, -0.0164,\n",
              "         -0.0604,  0.0187, -0.0589,  0.0067, -0.0406,  0.0477, -0.0150,  0.0154,\n",
              "          0.0145,  0.0487,  0.0360,  0.0050,  0.0049,  0.0242, -0.0393,  0.0082],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.1387, -0.1269,  0.0565,  0.0118, -0.0433,  0.1761,  0.1101,  0.0761,\n",
              "          -0.0785,  0.0586,  0.0752, -0.0501, -0.0148, -0.1201, -0.0595, -0.0185,\n",
              "           0.0618, -0.0561, -0.1071,  0.1558, -0.1000,  0.1272, -0.0948, -0.0990,\n",
              "           0.1423,  0.0401,  0.0261,  0.0482, -0.1444,  0.0722,  0.0354,  0.1373],\n",
              "         [-0.1145,  0.0272,  0.0772, -0.1738,  0.1027, -0.0348, -0.1581,  0.0014,\n",
              "          -0.1730, -0.1705, -0.1656,  0.0014, -0.0045, -0.1125, -0.1674, -0.1219,\n",
              "          -0.0083, -0.0880, -0.1392,  0.1697, -0.0407, -0.1059, -0.1334, -0.0636,\n",
              "          -0.0898, -0.1115, -0.0950,  0.1590, -0.1088,  0.0569,  0.1639,  0.0370],\n",
              "         [-0.0324,  0.1298,  0.1524, -0.1035, -0.1272, -0.0732,  0.1578,  0.0470,\n",
              "           0.0309, -0.0117,  0.0424, -0.1237,  0.1100,  0.0386,  0.0323, -0.0636,\n",
              "          -0.1454,  0.1708,  0.0270,  0.0511,  0.0343, -0.1548,  0.0458,  0.0078,\n",
              "          -0.1021,  0.1035,  0.0008,  0.1592, -0.0915, -0.0053,  0.0057, -0.0090],\n",
              "         [-0.1060,  0.1151, -0.0503, -0.0933, -0.1430,  0.1392, -0.1315, -0.1428,\n",
              "          -0.1676, -0.1166,  0.0135, -0.0639, -0.0129, -0.1494, -0.0105,  0.0607,\n",
              "           0.1130,  0.1083, -0.1244,  0.1729, -0.1364, -0.1027, -0.0305, -0.0248,\n",
              "           0.0923,  0.0470, -0.0529,  0.1629, -0.0497, -0.1093, -0.0798, -0.0634],\n",
              "         [ 0.1510,  0.0281,  0.1438,  0.0771,  0.0765,  0.0227,  0.1302,  0.1285,\n",
              "           0.0493,  0.0010, -0.1377,  0.1268, -0.1093, -0.1165,  0.0308, -0.0127,\n",
              "           0.0077,  0.1761, -0.1065, -0.0495, -0.0327, -0.1168, -0.0146, -0.0631,\n",
              "           0.0905, -0.1141, -0.0553,  0.0404, -0.0656, -0.1291,  0.1654,  0.1266],\n",
              "         [ 0.1562, -0.0392, -0.0276,  0.0003,  0.1693,  0.1437,  0.0565, -0.0642,\n",
              "           0.1463,  0.0247,  0.1672, -0.1241, -0.1172, -0.0998,  0.1693, -0.0249,\n",
              "          -0.0994, -0.0879,  0.0959, -0.0605,  0.0985,  0.0744, -0.0256, -0.0802,\n",
              "          -0.1085, -0.1183,  0.0674,  0.1152, -0.1479, -0.0700, -0.0770, -0.0118],\n",
              "         [ 0.0433, -0.0382,  0.1096,  0.1463, -0.1524, -0.0463,  0.1365,  0.0591,\n",
              "          -0.0840,  0.1731, -0.1054, -0.1411,  0.1569, -0.0060,  0.0327,  0.0272,\n",
              "          -0.1021,  0.1214,  0.0396,  0.0931, -0.0977,  0.0237,  0.0220,  0.1355,\n",
              "          -0.0827,  0.1593,  0.1517, -0.1404, -0.1437,  0.0947,  0.1023, -0.0764],\n",
              "         [-0.1567, -0.0819,  0.0437, -0.0771,  0.1242,  0.1484, -0.0144,  0.0650,\n",
              "           0.1617, -0.0097,  0.0402,  0.1260,  0.0741, -0.1391,  0.1015, -0.0570,\n",
              "           0.1200, -0.1065,  0.1075,  0.0931, -0.0653,  0.1596, -0.1224,  0.1322,\n",
              "           0.0307,  0.1454,  0.1550, -0.0767, -0.1415, -0.0765, -0.0561, -0.0151],\n",
              "         [ 0.0445,  0.0343, -0.0344, -0.0663,  0.0549,  0.1686, -0.0245,  0.0087,\n",
              "           0.0244,  0.1342, -0.1613, -0.0075,  0.1591,  0.0572,  0.1348,  0.1638,\n",
              "          -0.0499, -0.1105, -0.1341, -0.0119,  0.1373,  0.1465,  0.0304, -0.0287,\n",
              "          -0.0614,  0.0920,  0.0089, -0.0467, -0.0364, -0.1284, -0.1084,  0.0911],\n",
              "         [ 0.1004,  0.0433,  0.0477,  0.1105,  0.1372, -0.0620,  0.1323,  0.0768,\n",
              "          -0.1422, -0.0844,  0.0304,  0.1390,  0.1598, -0.0355,  0.0392, -0.1760,\n",
              "          -0.0106, -0.0105,  0.1411, -0.0440, -0.0183, -0.0487,  0.0175, -0.0221,\n",
              "           0.0058, -0.0066,  0.1205,  0.0324, -0.0695,  0.0792,  0.0749, -0.0850]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0089,  0.0935,  0.0437,  0.0529,  0.0610,  0.1414, -0.0629,  0.0209,\n",
              "          0.1658, -0.1674], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(cnn_model,input_size=(3,32,32),device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEmOvSws0jDU",
        "outputId": "12a3bc98-6298-481f-9b58-2f029da8d2fe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
            "       BatchNorm2d-3           [-1, 16, 16, 16]              32\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "         MaxPool2d-5             [-1, 32, 8, 8]               0\n",
            "       BatchNorm2d-6             [-1, 32, 8, 8]              64\n",
            "            Conv2d-7             [-1, 64, 8, 8]          18,496\n",
            "         MaxPool2d-8             [-1, 64, 4, 4]               0\n",
            "       BatchNorm2d-9             [-1, 64, 4, 4]             128\n",
            "           Conv2d-10            [-1, 128, 4, 4]          73,856\n",
            "        MaxPool2d-11            [-1, 128, 2, 2]               0\n",
            "           Linear-12                  [-1, 512]         262,656\n",
            "           Linear-13                  [-1, 256]         131,328\n",
            "           Linear-14                   [-1, 32]           8,224\n",
            "           Linear-15                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 500,202\n",
            "Trainable params: 500,202\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.35\n",
            "Params size (MB): 1.91\n",
            "Estimated Total Size (MB): 2.27\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(params=cnn_model.parameters())"
      ],
      "metadata": {
        "id": "zvRMGWDm00DI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "WFtXre502SHU"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(TensorDataset(x_train.float(),y_train),batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "3Umv_6gd2Lpz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(TensorDataset(x_test.float(),y_test),batch_size=128,shuffle=False)"
      ],
      "metadata": {
        "id": "Bq596Q0x2abG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVunoZRm2kq9",
        "outputId": "52b98ad2-531e-4fa3-ed13-4e85cf2c5df0"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = cnn_model.to(device)"
      ],
      "metadata": {
        "id": "nRM0q4E13JSf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Jrfa4_p73wFr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(model, train_loader, opt):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    for batch, target in tqdm(train_loader):\n",
        "        batch = batch.float().to(device)\n",
        "        target = target.to(device)\n",
        "        #print(target.dtype)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        output = model(batch.float())\n",
        "        #print(output.dtype)\n",
        "\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "YQWOqjt535kU"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, test_loader, opt):\n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch, target in tqdm(test_loader):\n",
        "            batch = batch.float().to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(batch.float())\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            val_loss += loss.item()\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "nMq2MvwD39Bl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn_model.to(device)\n",
        "hist = {'train_loss':[], 'val_loss':[]}\n",
        "for epoch in range(25):\n",
        "    hist['train_loss'].append(training(model, train_loader,opt))\n",
        "    hist['val_loss'].append(validate(model, val_loader,opt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxOHTscL4CDZ",
        "outputId": "45a3abe6-b7f8-48e0-9aaf-8201c1826587"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 782/782 [00:05<00:00, 136.69it/s]\n",
            "100%|| 79/79 [00:00<00:00, 332.20it/s]\n",
            "100%|| 782/782 [00:05<00:00, 154.83it/s]\n",
            "100%|| 79/79 [00:00<00:00, 351.40it/s]\n",
            "100%|| 782/782 [00:04<00:00, 156.87it/s]\n",
            "100%|| 79/79 [00:00<00:00, 368.79it/s]\n",
            "100%|| 782/782 [00:04<00:00, 157.58it/s]\n",
            "100%|| 79/79 [00:00<00:00, 365.99it/s]\n",
            "100%|| 782/782 [00:04<00:00, 156.50it/s]\n",
            "100%|| 79/79 [00:00<00:00, 376.68it/s]\n",
            "100%|| 782/782 [00:05<00:00, 155.86it/s]\n",
            "100%|| 79/79 [00:00<00:00, 356.15it/s]\n",
            "100%|| 782/782 [00:05<00:00, 152.65it/s]\n",
            "100%|| 79/79 [00:00<00:00, 358.51it/s]\n",
            "100%|| 782/782 [00:05<00:00, 152.68it/s]\n",
            "100%|| 79/79 [00:00<00:00, 345.38it/s]\n",
            "100%|| 782/782 [00:05<00:00, 155.06it/s]\n",
            "100%|| 79/79 [00:00<00:00, 356.69it/s]\n",
            "100%|| 782/782 [00:05<00:00, 154.91it/s]\n",
            "100%|| 79/79 [00:00<00:00, 382.52it/s]\n",
            "100%|| 782/782 [00:04<00:00, 158.22it/s]\n",
            "100%|| 79/79 [00:00<00:00, 353.66it/s]\n",
            "100%|| 782/782 [00:04<00:00, 156.40it/s]\n",
            "100%|| 79/79 [00:00<00:00, 364.89it/s]\n",
            "100%|| 782/782 [00:05<00:00, 155.46it/s]\n",
            "100%|| 79/79 [00:00<00:00, 370.12it/s]\n",
            "100%|| 782/782 [00:04<00:00, 157.59it/s]\n",
            "100%|| 79/79 [00:00<00:00, 361.90it/s]\n",
            "100%|| 782/782 [00:04<00:00, 158.48it/s]\n",
            "100%|| 79/79 [00:00<00:00, 372.36it/s]\n",
            "100%|| 782/782 [00:04<00:00, 158.28it/s]\n",
            "100%|| 79/79 [00:00<00:00, 352.88it/s]\n",
            "100%|| 782/782 [00:05<00:00, 153.45it/s]\n",
            "100%|| 79/79 [00:00<00:00, 353.97it/s]\n",
            "100%|| 782/782 [00:04<00:00, 159.12it/s]\n",
            "100%|| 79/79 [00:00<00:00, 362.52it/s]\n",
            "100%|| 782/782 [00:05<00:00, 155.94it/s]\n",
            "100%|| 79/79 [00:00<00:00, 357.28it/s]\n",
            "100%|| 782/782 [00:04<00:00, 158.40it/s]\n",
            "100%|| 79/79 [00:00<00:00, 368.26it/s]\n",
            "100%|| 782/782 [00:04<00:00, 157.17it/s]\n",
            "100%|| 79/79 [00:00<00:00, 364.96it/s]\n",
            "100%|| 782/782 [00:05<00:00, 155.13it/s]\n",
            "100%|| 79/79 [00:00<00:00, 368.23it/s]\n",
            "100%|| 782/782 [00:04<00:00, 158.56it/s]\n",
            "100%|| 79/79 [00:00<00:00, 365.42it/s]\n",
            "100%|| 782/782 [00:04<00:00, 156.78it/s]\n",
            "100%|| 79/79 [00:00<00:00, 363.30it/s]\n",
            "100%|| 782/782 [00:05<00:00, 154.62it/s]\n",
            "100%|| 79/79 [00:00<00:00, 364.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xivQwbaL98GH",
        "outputId": "216ce5ae-577d-4174-8b10-a438fae4edcc"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_loss': [1393.0781267881393, 1211.2381179332733, 1125.515290260315, 1051.416538119316, 984.6025753617287, 926.1889035105705, 862.3060865998268, 801.6490242481232, 740.3767539858818, 683.8255159854889, 631.277863651514, 578.964638710022, 529.2356527149677, 485.2947681546211, 441.6101594865322, 409.7758908569813, 379.4746562540531, 344.75950214266777, 319.8270109295845, 296.06997656822205, 272.42320197075605, 258.23173474520445, 238.36968891322613, 224.43201610818505, 213.06642573699355], 'val_loss': [137.39476466178894, 119.74743986129761, 112.9001624584198, 113.07847654819489, 107.00183165073395, 104.90445590019226, 105.83711636066437, 109.06870901584625, 109.42035973072052, 117.30187392234802, 116.36667513847351, 127.84972786903381, 132.4256513118744, 134.5769271850586, 139.06925570964813, 149.45225036144257, 150.8348467350006, 165.14347505569458, 170.400444149971, 174.76184964179993, 191.4587972164154, 186.9757604598999, 198.0314930677414, 206.63910925388336, 206.04529643058777]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred_vals = cnn_model(x_test.float().to(device)).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "IY4JkaCO4P6l"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(final_pred_vals,axis =1)"
      ],
      "metadata": {
        "id": "wr86y6wf-u_-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "f4Gr7MFN-xks"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(preds,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRiUbaDd-zlc",
        "outputId": "16959447-f51f-413a-d0b9-be983f66cd15"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[537,  47,  70,  30,  31,  20,   6,  20, 134,  55],\n",
              "       [ 34, 582,  12,  15,   2,   4,   7,  11,  47, 147],\n",
              "       [ 87,  21, 376, 125, 140, 100,  91,  55,  36,  26],\n",
              "       [ 34,  35,  87, 291,  65, 211,  79,  49,  17,  26],\n",
              "       [ 65,  26, 183, 130, 523, 120, 127, 164,  46,  24],\n",
              "       [ 16,  16,  77, 176,  46, 352,  35,  61,  17,  12],\n",
              "       [ 22,  24,  91, 115,  76,  71, 602,  24,  15,  28],\n",
              "       [ 41,  23,  63,  66,  81,  95,  24, 567,  14,  43],\n",
              "       [116,  43,  15,  24,  24,  16,  14,  11, 614,  53],\n",
              "       [ 48, 183,  26,  28,  12,  11,  15,  38,  60, 586]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(preds,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAZhp6Uv-1f0",
        "outputId": "498403cc-41cf-4261-b460-e338ff7e7671"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.503"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    }
  ]
}